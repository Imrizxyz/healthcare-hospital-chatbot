# -*- coding: utf-8 -*-
"""Healthcare â€” Hospital Information Chatbot (RAG) Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TQco51jHczJhnWO184gOYpvMU6u_SuuD
"""

!pip install -q chromadb sentence-transformers spacy pandas gradio
!python -m spacy download en_core_web_sm

import os
import re
import pandas as pd
import spacy

from sentence_transformers import SentenceTransformer
from chromadb import Client
from chromadb.utils import embedding_functions

nlp = spacy.load("en_core_web_sm")
print("spaCy model loaded")

data = [
    {"question": "What are Cardiology OPD timings?", "answer": "Cardiology OPD runs from 9 AM to 5 PM, Monday to Saturday."},
    {"question": "How can I book an appointment?", "answer": "Appointments can be booked online via hospital website or at the reception desk."},
    {"question": "What are ICU visiting hours?", "answer": "ICU visiting hours are from 4 PM to 5 PM. Only two visitors are allowed."},
    {"question": "Is emergency service available 24/7?", "answer": "Yes, emergency services are available 24/7 at the hospital."},
    {"question": "What documents are needed for admission?", "answer": "You need a valid ID proof and previous medical records for admission."}
]

df = pd.DataFrame(data)
df

texts = df["answer"].astype(str).tolist()
metadatas = [{"question": q} for q in df["question"].astype(str).tolist()]
ids = [f"doc_{i}" for i in range(len(texts))]

print("Documents prepared:", len(texts))

model = SentenceTransformer("all-MiniLM-L6-v2")
print("Embedding model loaded")

embeddings = model.encode(texts, show_progress_bar=True).tolist()
print("Embeddings created")

from chromadb import Client

client = Client()
collection_name = "hospital_faqs"

# delete collection if already exists
try:
    client.delete_collection(collection_name)
except:
    pass

# create collection WITHOUT embedding_function
collection = client.create_collection(name=collection_name)

# add documents with precomputed embeddings
collection.add(
    ids=ids,
    documents=texts,
    metadatas=metadatas,
    embeddings=embeddings
)

print("Chroma collection created with", len(ids), "documents")

PII_PATTERNS = [
    re.compile(r"\b\d{10}\b"),      # phone number
    re.compile(r"\b\d{12}\b"),      # Aadhaar-like
    re.compile(r"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}")
]

REFUSAL_MESSAGE = "Sorry, I cannot share personal or clinical information due to privacy rules."

def redact_pii(text):
    for p in PII_PATTERNS:
        text = p.sub("[REDACTED]", text)
    return text

def has_person_name(text):
    doc = nlp(text)
    for ent in doc.ents:
        if ent.label_ == "PERSON":
            return True
    return False

def retrieve_answer(user_query, k=2):
    cleaned = redact_pii(user_query)

    if has_person_name(cleaned):
        return REFUSAL_MESSAGE

    query_embedding = model.encode([cleaned]).tolist()

    results = collection.query(
        query_embeddings=query_embedding,
        n_results=k
    )

    docs = results["documents"][0]

    if not docs:
        return "Sorry, I could not find relevant hospital information."

    return docs[0]

print(retrieve_answer("What are Cardiology OPD timings?"))
print(retrieve_answer("Tell me Rahul Rawat ward number"))
print(retrieve_answer("Is emergency available?"))

